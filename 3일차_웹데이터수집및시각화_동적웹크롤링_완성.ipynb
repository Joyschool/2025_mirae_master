{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joyschool/2025_mirae_master/blob/main/3%EC%9D%BC%EC%B0%A8_%EC%9B%B9%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%88%98%EC%A7%91%EB%B0%8F%EC%8B%9C%EA%B0%81%ED%99%94_%EB%8F%99%EC%A0%81%EC%9B%B9%ED%81%AC%EB%A1%A4%EB%A7%81_%EC%99%84%EC%84%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fJ5O84wPYPL",
      "metadata": {
        "id": "4fJ5O84wPYPL"
      },
      "source": [
        "# 웹 데이터 수집 및 시각화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5EeG6TDjPY8n",
      "metadata": {
        "id": "5EeG6TDjPY8n"
      },
      "source": [
        "## 1. 웹 크롤링으로 데이터 수집 -동적 웹 크롤링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GlUTfO8OPZE1",
      "metadata": {
        "id": "GlUTfO8OPZE1"
      },
      "source": [
        "### 3) 동적 크롤링(**Visual Studio Code 사용**)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfff7426",
      "metadata": {
        "id": "dfff7426"
      },
      "source": [
        "- 공식페이지: https://www.selenium.dev/\n",
        "- 참고: https://wikidocs.net/198942\n",
        "- beautifulsoup 사용법 : https://wikidocs.net/85739\n",
        "    - **select_one** 은 찾은 html 중 가장 첫번째 html 을 가져오고\n",
        "    - **select** 는 찾은 모든 html 을 리스트 형태로 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e1b434",
      "metadata": {
        "id": "61e1b434"
      },
      "source": [
        "- **한글 폰트 지정하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf54b67d",
      "metadata": {
        "id": "cf54b67d"
      },
      "outputs": [],
      "source": [
        "# 코랩에서 한글 폰트 종류와 이름이 win과 다를 수 있다!!!\n",
        "# 코랩: NanumGothic, 윈도우: Malgun Gothic\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.family': 'Malgun Gothic',\n",
        "                     'font.size': 12,\n",
        "                     'figure.figsize': (6, 4),\n",
        "                     'axes.unicode_minus':  False }) # 폰트 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73553a7",
      "metadata": {
        "id": "c73553a7"
      },
      "source": [
        "#### 1.라이브러리 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89d7109",
      "metadata": {
        "id": "b89d7109",
        "outputId": "a674f31e-571f-4a14-c015-20fa654057c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in c:\\python\\python312\\lib\\site-packages (4.19.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in c:\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.1.0)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\python\\python312\\lib\\site-packages (from selenium) (0.25.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\python\\python312\\lib\\site-packages (from selenium) (2023.11.17)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\python\\python312\\lib\\site-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in c:\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in c:\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in c:\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
            "Requirement already satisfied: outcome in c:\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in c:\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: pycparser in c:\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~atplotlib (C:\\python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~atplotlib (C:\\python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~atplotlib (C:\\python\\Python312\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "# 동적 크롤링을 위한 라이브러리\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a629dc77",
      "metadata": {
        "id": "a629dc77",
        "scrolled": true,
        "outputId": "72469a63-e1ae-4f38-e30d-790737bc5218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromedriver-autoinstaller in c:\\python\\python312\\lib\\site-packages (0.6.4)\n",
            "Requirement already satisfied: packaging>=23.1 in c:\\python\\python312\\lib\\site-packages (from chromedriver-autoinstaller) (23.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~atplotlib (C:\\python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~atplotlib (C:\\python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~atplotlib (C:\\python\\Python312\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install chromedriver-autoinstaller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "281f2c4e",
      "metadata": {
        "id": "281f2c4e",
        "outputId": "663549f7-fb82-4a7e-d1f6-2661865af2af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4.19.0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import selenium\n",
        "selenium.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd87b66",
      "metadata": {
        "id": "ebd87b66"
      },
      "source": [
        "#### 2.ChromeDriver 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf60499d",
      "metadata": {
        "id": "bf60499d"
      },
      "source": [
        "* ChromeDriver 사용방법\n",
        "    - 방법1 : **chromedriver-autoinstaller 라이브러리 사용해서 버전 고려 안하기(쉬움)**\n",
        "    - 방법2 : 버전 업데이트마다 PC에 ChromeDriver.exe 드라이버 재설치(복잡함)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17142302",
      "metadata": {
        "id": "17142302"
      },
      "source": [
        "* ChromeDriver 동작 확인\n",
        "    - 크롬 브라우저에 **'Chrome이 자동화된 테스트 소프트웨어에 의해 제어되고 있습니다'** 문구와 함께 화면이 뜨면 성공!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa86b594",
      "metadata": {
        "id": "fa86b594"
      },
      "outputs": [],
      "source": [
        "import chromedriver_autoinstaller # chrome driver 자동 설치 라이브러리\n",
        "from selenium import webdriver\n",
        "\n",
        "# chrome driver를 자동으로 설치함\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "options = webdriver.ChromeOptions() # Browser 세팅하기\n",
        "options.add_argument('lang=ko_KR') # 사용언어 한국어\n",
        "options.add_argument('disable-gpu') # 하드웨어 가속 안함\n",
        "# options.add_argument('headless') # 창 숨기기\n",
        "\n",
        "# # 브라우저 세팅\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# 브라우저에 URL 호출하기\n",
        "driver.get(url='https://www.naver.com/')\n",
        "\n",
        "# 브라우저 탭 닫기\n",
        "driver.close()\n",
        "\n",
        "# 브라우저 종료하기 (탭 모두 종료)\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc52e0c5",
      "metadata": {
        "id": "bc52e0c5"
      },
      "source": [
        "- 간단하게 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e5a15a",
      "metadata": {
        "id": "c0e5a15a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# 웹페이지로 이동\n",
        "driver.get('https://www.naver.com/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac30b7d",
      "metadata": {
        "id": "bac30b7d"
      },
      "source": [
        "---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ff3753",
      "metadata": {
        "id": "87ff3753"
      },
      "source": [
        "#### 3. Selenium을 사용하여 동적 웹 페이지와 상호작용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6170ea5e",
      "metadata": {
        "id": "6170ea5e"
      },
      "source": [
        "* **(클릭 이벤트를 위한 xpath 복사)작업 순서**\n",
        "    - 크롬에서 target 페이지 접속(https://www.naver.com/)\n",
        "    - F12 눌러 오른쪽 영역에 개발자 페이지 나타나도록 함(html코드 나타남)\n",
        "    - ctrl+shift+c 누른 상태에서 클릭 이벤트 발생할 곳 찾아 마우스 클릭\n",
        "    - 해당 html코드 영역에서 마우스 오른쪽키 누르고 copy>copy.xpath 메뉴 선택하여 이벤트 코드 클립보드에 복사\n",
        "    - driver.find_element(By.XPATH, '복사된 내용 붙여넣기').click()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1a352f",
      "metadata": {
        "id": "6b1a352f"
      },
      "source": [
        "* **[사용방법] 버튼(링크) 클릭**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7005f89",
      "metadata": {
        "id": "f7005f89",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# 웹페이지로 이동\n",
        "driver.get('https://www.naver.com/')\n",
        "\n",
        "# 클릭(copy.xpath 이용)  //*[@id=\"search-btn\"]\n",
        "search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]')\n",
        "search_button.click()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56040955",
      "metadata": {
        "id": "56040955"
      },
      "source": [
        "#### [1단계] 네이버 메인페이지에서 검색어 입력하고 버튼 클릭하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c43c66f",
      "metadata": {
        "id": "8c43c66f",
        "outputId": "67725a2f-5967-4099-d134-f5c288cdd12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "현재URL : https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EB%85%B8%EB%B2%A8%EB%AC%B8%ED%95%99%EC%83%81\n"
          ]
        }
      ],
      "source": [
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# chrome driver를 자동으로 설치함\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "def naver_main_search(driver, keyword):\n",
        "    driver.get('https://www.naver.com/') # 웹페이지 로드\n",
        "    search_box = driver.find_element(By.XPATH, '//*[@id=\"query\"]')  # 검색 키워드 영역\n",
        "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]') # 검색 버튼\n",
        "    search_keyword = keyword  # 키워드\n",
        "    search_box.send_keys(search_keyword)\n",
        "    search_button.click()\n",
        "\n",
        "# 1.네이버 메인 검색\n",
        "keyword = '노벨문학상'\n",
        "naver_main_search(driver, keyword)\n",
        "print(f'현재URL : {driver.current_url}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3462821",
      "metadata": {
        "id": "f3462821"
      },
      "source": [
        "#### [2단계] 네이버 검색 결과 페이지에서 다시 버튼 클릭\n",
        "- 버튼 클릭 위치 확인(xPath) : 마우스오른쪽버튼 > Copy >Copy xPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0f56d8",
      "metadata": {
        "id": "3b0f56d8",
        "outputId": "5295693e-fc51-44df-b540-dac373d94905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1단계 : 검색어 넣고 네이버 메인 검색......\n",
            "\n",
            "2단계 : 검색 결과에서 탭 선택......\n",
            "      currnet_url=https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EB%85%B8%EB%B2%A8%EC%83%81\n"
          ]
        }
      ],
      "source": [
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# chrome driver를 자동으로 설치함\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# [CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "def naver_main_search(driver, keyword):\n",
        "    print('\\n1단계 : 검색어 넣고 네이버 메인 검색......')\n",
        "    driver.get('https://www.naver.com/') # 웹페이지 로드\n",
        "    search_box = driver.find_element(By.XPATH, '//*[@id=\"query\"]')  # 검색 키워드 영역\n",
        "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]') # 검색 버튼\n",
        "    search_keyword = keyword  # 키워드\n",
        "    search_box.send_keys(search_keyword) # 검색창에 검색어 반영\n",
        "    search_button.click() # 클릭 이벤트\n",
        "\n",
        "# [CODE 2] : 검색 결과에서 다른 탭 선택\n",
        "def naver_main_search_tab(driver, url, xpath):\n",
        "    print('\\n2단계 : 검색 결과에서 탭 선택......')\n",
        "    print(f'      currnet_url={driver.current_url}')\n",
        "    driver.get(url) # 해당 웹페이지 로드\n",
        "    search_button = driver.find_element(By.XPATH, xpath) # target xpath\n",
        "    search_button.click()\n",
        "\n",
        "\n",
        "keyword = input('페이지 검색어 입력: ')\n",
        "\n",
        "# 1.[CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "naver_main_search(driver, keyword)\n",
        "\n",
        "# 2.[CODE 2] : 검색 결과에서 다른 탭 선택 ( 마우스오른쪽버튼 > Copy >Copy xPath)\n",
        "naver_main_search_tab(driver, driver.current_url, '//*[@id=\"lnb\"]/div[1]/div/div[1]/div/div[1]/div[1]/a' )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d15d93",
      "metadata": {
        "id": "f0d15d93"
      },
      "source": [
        "#### [3단계] 네이버 검색 다른 탭 정보 추출하기 : 제목, 상세설명, 링크\n",
        "- 추출할 정보의 정확한 위치 확인 후 --> 적절히 코드 수정후 실행한다.\n",
        "- 키워드 : **노벨문학상**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "978ecf6f",
      "metadata": {
        "id": "978ecf6f",
        "outputId": "c99dbc36-2dbc-48c6-cd08-94805ba2f3b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1단계 : 검색어 넣고 네이버 메인 검색......\n",
            "\n",
            "2단계 : 검색 결과에서 다른 탭 선택......\n",
            "      currnet_url=https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EB%85%B8%EB%B2%A8%EB%AC%B8%ED%95%99%EC%83%81\n",
            "\n",
            "3단계 : 다른 탭 페이지에서 정보(제목,상세,링크) 추출......\n",
            "'한강이 감동했다는 그 노래' 차트 역주행…가요계도 한강 열풍\n",
            "노벨문학상 번역가의 품격…소감 대신 '한강의 세 문장' 공유\n",
            "노벨 문학상 '한강' 언급한 日언론 \"국경 넘어 보편성 지녀\"\n",
            "'특혜 입학' 논란 정유라 \"역사 왜곡 소설로 노벨문학상 수상, 의미 있는지 모르겠다\"\n",
            "'한강 노벨상' 가장 먼저 알았다…노벨상 초상화 그린 화가는 누구?\n",
            "'노벨문학상' 한강 운영 독립서점 임시 휴점…수상 축하 발길 이어져\n",
            "[단독]노벨상 마을잔치 소식에…한강, 부친에게 “안 했으면 좋겠다”\n",
            "\"한강이 감동한 노래\" 한 마디에…무서운 속도로 '역주행'\n",
            "노벨문학상 배출국의 이면…한 달 책 구매액 1만원 못 미쳐\n",
            "주영한국문화원, 노벨문학상 한강 특별 코너 마련\n",
            "\n",
            "완료 : 추출된 정보 표로 만들기......\n",
            "Total[10 건]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>desc</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'한강이 감동했다는 그 노래' 차트 역주행…가요계도 한강 열풍</td>\n",
              "      <td>악동뮤지션 '어떻게 이별까지∼' 멜론서 연일 순위 상승 한강 작품 따라 예명 지은 ...</td>\n",
              "      <td>https://www.yna.co.kr/view/AKR2024101203460000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>노벨문학상 번역가의 품격…소감 대신 '한강의 세 문장' 공유</td>\n",
              "      <td>노벨문학상을 수상한 한강의 작품을 세계에 알린 주역으로 꼽히는 영국인 번역가 데버라...</td>\n",
              "      <td>https://www.joongang.co.kr/article/25283918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>노벨 문학상 '한강' 언급한 日언론 \"국경 넘어 보편성 지녀\"</td>\n",
              "      <td>일본 아사히신문은 한국 한강 작가가 노벨문학상을 수상한 것과 관련해 \"전쟁, 격차,...</td>\n",
              "      <td>https://view.asiae.co.kr/article/2024101316231...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'특혜 입학' 논란 정유라 \"역사 왜곡 소설로 노벨문학상 수상, 의미 있는지 모르겠다\"</td>\n",
              "      <td>최윤서 인턴 기자 = 이화여대 특혜입학으로 입학이 취소됐던 최서원(개명 전 최순실)...</td>\n",
              "      <td>https://www.newsis.com/view/NISX20241013_00029...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'한강 노벨상' 가장 먼저 알았다…노벨상 초상화 그린 화가는 누구?</td>\n",
              "      <td>소설가 한강이 한국 최초로 노벨 문학상을 수상하자 그의 노벨상 초상화를 그린 화가 ...</td>\n",
              "      <td>https://www.news1.kr/world/europe/5566463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              title  \\\n",
              "0                '한강이 감동했다는 그 노래' 차트 역주행…가요계도 한강 열풍   \n",
              "1                 노벨문학상 번역가의 품격…소감 대신 '한강의 세 문장' 공유   \n",
              "2                노벨 문학상 '한강' 언급한 日언론 \"국경 넘어 보편성 지녀\"   \n",
              "3  '특혜 입학' 논란 정유라 \"역사 왜곡 소설로 노벨문학상 수상, 의미 있는지 모르겠다\"   \n",
              "4             '한강 노벨상' 가장 먼저 알았다…노벨상 초상화 그린 화가는 누구?   \n",
              "\n",
              "                                                desc  \\\n",
              "0  악동뮤지션 '어떻게 이별까지∼' 멜론서 연일 순위 상승 한강 작품 따라 예명 지은 ...   \n",
              "1  노벨문학상을 수상한 한강의 작품을 세계에 알린 주역으로 꼽히는 영국인 번역가 데버라...   \n",
              "2  일본 아사히신문은 한국 한강 작가가 노벨문학상을 수상한 것과 관련해 \"전쟁, 격차,...   \n",
              "3  최윤서 인턴 기자 = 이화여대 특혜입학으로 입학이 취소됐던 최서원(개명 전 최순실)...   \n",
              "4  소설가 한강이 한국 최초로 노벨 문학상을 수상하자 그의 노벨상 초상화를 그린 화가 ...   \n",
              "\n",
              "                                                link  \n",
              "0  https://www.yna.co.kr/view/AKR2024101203460000...  \n",
              "1        https://www.joongang.co.kr/article/25283918  \n",
              "2  https://view.asiae.co.kr/article/2024101316231...  \n",
              "3  https://www.newsis.com/view/NISX20241013_00029...  \n",
              "4          https://www.news1.kr/world/europe/5566463  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# chrome driver를 자동으로 설치함\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "\n",
        "# [CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "def naver_main_search(driver, keyword):\n",
        "    print('\\n1단계 : 검색어 넣고 네이버 메인 검색......')\n",
        "    driver.get('https://www.naver.com/') # 웹페이지 로드\n",
        "    search_box = driver.find_element(By.XPATH, '//*[@id=\"query\"]')  # 검색 키워드 영역\n",
        "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]') # 검색 버튼\n",
        "    search_keyword = keyword  # 키워드\n",
        "    search_box.send_keys(search_keyword)\n",
        "    search_button.click()\n",
        "\n",
        "# [CODE 2] : 검색 결과에서 다른 탭(첫번째 탭) 선택\n",
        "def naver_main_search_tab(driver, url, xpath):\n",
        "    print('\\n2단계 : 검색 결과에서 다른 탭 선택......')\n",
        "    print(f'      currnet_url={driver.current_url}')\n",
        "    driver.get(url) # 해당 웹페이지 로드\n",
        "    search_button = driver.find_element(By.XPATH, xpath) # target xpath\n",
        "    search_button.click()\n",
        "\n",
        "# [CODE 3] : 다른 탭 페이지에서 정보(ex: 제목,상세,링크) 추출\n",
        "def naver_html_parse(html):\n",
        "    print('\\n3단계 : 다른 탭 페이지에서 정보(제목,상세,링크) 추출......')\n",
        "    t_list, d_list, link_list = [], [], []\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    ul = soup.select_one('ul.list_news._infinite_list') #공백에 있을 경우 . 사용\n",
        "\n",
        "    # 제목, 링크 추출하기\n",
        "    contents = ul.select('li > div > div > div.news_contents > a')\n",
        "    for content in contents:\n",
        "        #  class가 'news_tit'인 것을 찾음\n",
        "        if 'news_tit' in content.get('class', []):  # class 속성에 'news_tit'이 있는지 확인\n",
        "            t_list.append(content.attrs['title'])   # 제목\n",
        "            link_list.append(content.attrs['href']) # href 링크\n",
        "\n",
        "    # 상세설명 추출하기\n",
        "    contents = ul.select('li > div > div > div.news_contents > div > div > a') # 상세설명\n",
        "    for content in contents:\n",
        "        d_list.append(content.get_text())\n",
        "\n",
        "    # DataFrame으로 만들기\n",
        "    data = {'title': t_list, 'desc':d_list,'link':link_list}\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "\n",
        "keyword = input('페이지 검색어 입력: ')\n",
        "\n",
        "# 1.[CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "naver_main_search(driver, keyword)\n",
        "\n",
        "# 2.[CODE 2] : 검색 결과에서 다른 탭 선택\n",
        "naver_main_search_tab(driver, driver.current_url, '//*[@id=\"lnb\"]/div[1]/div/div[1]/div/div[1]/div[1]/a/i' )\n",
        "html = driver.page_source  # 페이지 소스 가져오기\n",
        "\n",
        "# 3.[CODE 3] : 다른 탭 페이지에서 정보(ex: 제목,상세,링크) 추출\n",
        "df = naver_html_parse(html)\n",
        "print('\\n완료 : 추출된 정보 표로 만들기......')\n",
        "print(f'Total[{len(df)} 건]')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84b91436",
      "metadata": {
        "id": "84b91436"
      },
      "source": [
        "#### [4단계] 페이지 자동 스크롤링한 후 정보 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658def73",
      "metadata": {
        "id": "658def73"
      },
      "outputs": [],
      "source": [
        "# 웹 드라이버매니저 설치\n",
        "!pip install webdriver-manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c9b2d8",
      "metadata": {
        "id": "58c9b2d8"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# 크롬 드라이버 자동 업데이트\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "#브라우저 꺼짐 방지\n",
        "chrome_options = Options()\n",
        "chrome_options.add_experimental_option(\"detach\", True)\n",
        "\n",
        "# 불필요한 에러 메시지 없애기\n",
        "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "# [CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "def naver_main_search(driver, keyword):\n",
        "    print('\\n1단계 : 검색어 넣고 네이버 메인 검색......')\n",
        "    driver.get('https://www.naver.com/') # 웹페이지 로드\n",
        "    search_box = driver.find_element(By.XPATH, '//*[@id=\"query\"]')  # 검색 키워드 영역\n",
        "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]') # 검색 버튼\n",
        "    print(f'search_box : {search_box}')\n",
        "    search_keyword = keyword  # 키워드\n",
        "    search_box.send_keys(search_keyword)\n",
        "    search_button.click()\n",
        "\n",
        "# [CODE 2] : 검색 결과에서 다른 탭 선택\n",
        "def naver_main_search_tab(driver, url, xpath):\n",
        "    print('\\n2단계 : 검색 결과에서 다른 탭 선택......')\n",
        "    print(f'      currnet_url={driver.current_url}')\n",
        "    driver.get(url) # 해당 웹페이지 로드\n",
        "    search_button = driver.find_element(By.XPATH, xpath) # target xpath\n",
        "    search_button.click()\n",
        "\n",
        "    # 페이지 자동 스크롤하기(3번)\n",
        "    print('2단계 : 페이지 자동 스크롤...')\n",
        "    actions = driver.find_element(By.CSS_SELECTOR, 'body')\n",
        "    time.sleep(2)\n",
        "    for _ in range(3):\n",
        "        actions.send_keys(Keys.END)\n",
        "        print('       page scroll...' )\n",
        "        time.sleep(2)\n",
        "\n",
        "# [CODE 3] : VIEW탭 페이지에서 정보(제목,상세,링크) 추출\n",
        "def naver_html_parse(html):\n",
        "    print('\\n3단계 : 다른 탭 페이지에서 정보(제목,상세,링크) 추출......')\n",
        "    t_list, d_list, link_list = [], [], []\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    #main_pack > section > div.api_subject_bx > ul > li:nth-child(1) > div > div.detail_box > div.title_area > a\n",
        "    ul = soup.select_one('ul.lst_view._fe_view_infinite_scroll_append_target') #공백에 있을 경우 . 사용\n",
        "    # 제목, 링크 추출하기\n",
        "    contents = ul.select('li > div > div > div.title_area > a')\n",
        "    for content in contents:\n",
        "        t_list.append(content.get_text())       # 제목\n",
        "    # 상세설명 추출하기\n",
        "    contents = ul.select('li > div > div > div.dsc_area > a') # 상세설명\n",
        "    for content in contents:\n",
        "        link_list.append(content.attrs['href']) # href 링크\n",
        "        d_list.append(content.get_text())\n",
        "\n",
        "    # DataFrame으로 만들기\n",
        "    data = {'title': t_list, 'desc':d_list,'link':link_list}\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "\n",
        "keyword = input('페이지 검색어 입력: ')\n",
        "\n",
        "# 1.[CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "naver_main_search(driver, keyword)\n",
        "\n",
        "# 2.[CODE 2] : 검색 결과에서 VIEW 탭 선택\n",
        "naver_main_search_tab(driver, driver.current_url, '//*[@id=\"lnb\"]/div[1]/div/div[1]/div/div[1]/div[1]/a/i' )\n",
        "html = driver.page_source  # 페이지 소스 가져오기\n",
        "\n",
        "# 3.[CODE 3] : 다른 탭 페이지에서 정보(제목,상세,링크) 추출\n",
        "df = naver_html_parse(html)\n",
        "print('\\n완료 : 추출된 정보 표로 만들기......')\n",
        "print(f'Total[{len(df)} 건]')\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4d5d79",
      "metadata": {
        "id": "5a4d5d79",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93264ee",
      "metadata": {
        "id": "c93264ee"
      },
      "source": [
        "-------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882b6a04",
      "metadata": {
        "id": "882b6a04"
      },
      "source": [
        "#### [실습]  커피빈매장 정보 크롤링하여 파일로 저장하기\n",
        "- 아래 사이트를 이용해 호출해야할 자바스크립트 함수를 확인하다.\n",
        "- https://www.coffeebeankorea.com\n",
        "- https://www.coffeebeankorea.com/store/store.asp\n",
        "- (매장 번호로) 자세히보기: javascript:storePop2('374');\n",
        "- chromedriver.exe 파일 위치는 코드와 동일한 위치에 놓는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889f4ed3",
      "metadata": {
        "id": "889f4ed3"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from selenium import webdriver\n",
        "import time\n",
        "\n",
        "MAX = 10     # 추출 데이터 건수\n",
        "FILE = './CoffeeBean_매장정보.csv'\n",
        "\n",
        "#[CODE 1]\n",
        "def getStoreInfo():\n",
        "    CoffeeBean_URL = \"https://www.coffeebeankorea.com/store/store.asp\"\n",
        "\n",
        "    # 드라이버 초기화\n",
        "    driver = webdriver.Chrome()\n",
        "\n",
        "    result = []  # 데이터 저장 변수\n",
        "    total, cnt = 370, 0\n",
        "    for i in range(1, total+1):  #매장 수 만큼(370) 반복\n",
        "        driver.get(CoffeeBean_URL)\n",
        "        time.sleep(1)  #웹페이지 연결할 동안 1초 대기\n",
        "        try:\n",
        "            print(f'read[{i}]')\n",
        "            driver.execute_script(\"storePop2(%d)\" %i)\n",
        "            time.sleep(1) #스크립트 실행 할 동안 1초 대기\n",
        "\n",
        "            html = driver.page_source\n",
        "            soup = BeautifulSoup(html, 'html.parser')\n",
        "            store_name_h2 = soup.select(\"div.store_txt > h2\")\n",
        "            store_name = store_name_h2[0].string  #매장 이름\n",
        "\n",
        "            store_info = soup.select(\"div.store_txt > table.store_table > tbody > tr > td\")\n",
        "            store_address_list = list(store_info[2])\n",
        "            store_address = store_address_list[0]  #매장 주소\n",
        "\n",
        "            store_phone = store_info[3].string     #매장 전화번호\n",
        "            result.append([store_name]+[store_address]+[store_phone])\n",
        "            cnt += 1\n",
        "            # 매장정보 가져온 데이터 출력하기\n",
        "            print(\"save[%3d] %3d - %s\" % (cnt, i, store_name))\n",
        "\n",
        "             # MAX값에 해당하는 건수 만큼만 실행하기\n",
        "            if cnt >= MAX:\n",
        "                break\n",
        "\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return result\n",
        "\n",
        "#---------------\n",
        "# main\n",
        "#---------------\n",
        "#[CODE 0]\n",
        "def main():\n",
        "    result = []\n",
        "    print('CoffeeBean store crawling >>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
        "    result = getStoreInfo()  #[매장 추출 함수]호출하기   #[CODE 1] 호출\n",
        "    coffeebean_tbl = pd.DataFrame(result, columns=('store', 'address','phone'))\n",
        "    coffeebean_tbl.to_csv(FILE, encoding='cp949', mode='w', index=True)  # 파일로 저장하기\n",
        "    del result[:]\n",
        "    return coffeebean_tbl\n",
        "\n",
        "\n",
        "df = main() #[CODE 0] 호출\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641f3d97",
      "metadata": {
        "id": "641f3d97"
      },
      "source": [
        "----------------------"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}